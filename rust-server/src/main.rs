use anyhow::Result;
use axum::{
    extract::{ConnectInfo, Query, State},
    http::{header, HeaderMap, StatusCode},
    response::{IntoResponse, Response},
    routing::{get, post},
    Json, Router,
};
use axum_server::tls_rustls::RustlsConfig;
use futures::StreamExt;
use mime_guess::from_path;
use path_clean::PathClean;
use pathdiff::diff_paths;
use rand::seq::SliceRandom;
use serde::{Deserialize, Serialize};
use sqlx::{sqlite::SqlitePoolOptions, Pool, Row, Sqlite};
use std::{
    collections::{HashMap, HashSet},
    env,
    net::SocketAddr,
    path::{Path, PathBuf},
    sync::Arc,
    time::{SystemTime, UNIX_EPOCH},
};
use tokio::sync::RwLock;
use tower_http::cors::CorsLayer;
use walkdir::WalkDir;

// --- å¸¸é‡ä¸é…ç½® ---
const ALLOWED_EXTENSIONS: &[&str] = &["jpg", "jpeg", "png", "gif", "webp", "bmp"];

#[derive(Clone)]
struct AppState {
    db: Pool<Sqlite>,
    root_dir: Arc<PathBuf>,
    allow_parent_dir_access: Arc<RwLock<bool>>,
    external_synced_paths_this_boot: Arc<RwLock<HashSet<String>>>,
    user_sessions: Arc<RwLock<HashMap<String, Vec<String>>>>,
    log_api_file_requests: bool,
}

// --- æ•°æ®æ¨¡å‹ ---

#[derive(Debug, Deserialize)]
struct PlaylistRequest {
    paths: Vec<String>,
    #[serde(default = "default_sort")]
    sort: String,
    #[serde(default = "default_orientation")]
    orientation: String,
    #[serde(default = "default_direction")]
    direction: String,
    current_path: Option<String>,
}

#[derive(Debug, Deserialize)]
struct RestorePlaylistRequest {
    playlist: Vec<String>,
    #[serde(default)]
    current_index: usize,
}

#[derive(Debug, Deserialize)]
struct RuntimeConfigRequest {
    allow_parent_dir_access: bool,
}

#[derive(Debug, Deserialize)]
struct BrowseQuery {
    #[serde(default)]
    path: String,
}

#[derive(Debug, Deserialize)]
struct FileQuery {
    path: String,
}

#[derive(Debug, Serialize)]
struct BrowseItem {
    name: String,
    path: String,
    #[serde(rename = "type")]
    item_type: String,
}

#[derive(Debug, Serialize)]
struct BrowseResponse {
    #[serde(rename = "currentPath")]
    current_path: String,
    items: Vec<BrowseItem>,
}

#[derive(Debug, Serialize)]
struct SessionStatusResponse {
    has_session: bool,
    source: Option<String>,
    playlist_size: usize,
}

#[derive(Debug, Serialize)]
struct SessionPlaylistResponse {
    has_session: bool,
    source: Option<String>,
    playlist_size: usize,
    playlist: Vec<String>,
}

#[derive(sqlx::FromRow, Clone, Debug)]
struct ImageMetadata {
    path: String,
    mtime: f64,
    width: u32,
    height: u32,
    is_landscape: bool,
}

fn default_sort() -> String { "shuffle".to_string() }
fn default_orientation() -> String { "Both".to_string() }
fn default_direction() -> String { "forward".to_string() }

fn path_to_rel_string(root_dir: &Path, full_path: &Path) -> String {
    diff_paths(full_path, root_dir)
        .unwrap_or_else(|| PathBuf::from(""))
        .to_string_lossy()
        .replace('\\', "/")
}

// --- è¾…åŠ©å‡½æ•° ---

fn normalize_rel_path(path: &str) -> String {
    path.replace('\\', "/")
        .trim()
        .trim_start_matches('/')
        .trim_end_matches('/')
        .replace("/./", "/")
}

fn resolve_full_path(root_dir: &Path, rel_path: &str) -> PathBuf {
    root_dir.join(rel_path).clean()
}

fn env_flag_enabled(name: &str) -> bool {
    env::var(name)
        .map(|v| {
            matches!(
                v.trim().to_ascii_lowercase().as_str(),
                "1" | "true" | "yes" | "on"
            )
        })
        .unwrap_or(false)
}

fn is_under_root(root_dir: &Path, full_path: &Path) -> bool {
    full_path.starts_with(root_dir)
}

fn is_image_ext(path: &Path) -> bool {
    path.extension()
        .and_then(|e| e.to_str())
        .map(|e| ALLOWED_EXTENSIONS.iter().any(|ext| ext.eq_ignore_ascii_case(e)))
        .unwrap_or(false)
}

fn escape_like_pattern(value: &str) -> String {
    value.replace('\\', "\\\\").replace('%', "\\%").replace('_', "\\_")
}

fn parent_folder(path: &str) -> String {
    Path::new(path)
        .parent()
        .map(|p| p.to_string_lossy().replace('\\', "/"))
        .unwrap_or_default()
}

fn file_stem_from_rel_path(path: &str) -> String {
    Path::new(path)
        .file_stem()
        .map(|s| s.to_string_lossy().to_string())
        .unwrap_or_default()
}

fn strip_trailing_index_suffix(name: &str) -> String {
    if let Some((prefix, suffix)) = name.rsplit_once(" (") {
        if suffix.ends_with(')') {
            let digits = &suffix[..suffix.len() - 1];
            if !digits.is_empty() && digits.chars().all(|c| c.is_ascii_digit()) {
                return prefix.trim_end().to_string();
            }
        }
    }
    name.to_string()
}

fn folder_first_image_prefix(items: &[ImageMetadata]) -> String {
    if items.is_empty() {
        return String::new();
    }
    let stem = file_stem_from_rel_path(&items[0].path);
    strip_trailing_index_suffix(&stem)
}

fn folder_mtime(root_dir: &Path, parent: &str) -> f64 {
    let folder_path = if parent.is_empty() {
        root_dir.to_path_buf()
    } else {
        resolve_full_path(root_dir, parent)
    };

    folder_path
        .metadata()
        .ok()
        .and_then(|m| m.modified().ok())
        .and_then(|t| t.duration_since(UNIX_EPOCH).ok())
        .map(|d| d.as_secs_f64())
        .unwrap_or(0.0)
}

async fn sync_external_path_to_db(pool: &Pool<Sqlite>, root_dir: &Path, rel_path: &str) -> Result<()> {
    let normalized = normalize_rel_path(rel_path);
    if normalized.is_empty() {
        return Ok(());
    }

    let full_path = resolve_full_path(root_dir, &normalized);
    let root_clone = root_dir.to_path_buf();

    let scanned: Vec<ImageMetadata> = tokio::task::spawn_blocking(move || {
        let mut results = Vec::new();

        if !full_path.exists() {
            return results;
        }

        if full_path.is_file() {
            if let Some(meta) = process_image_metadata_sync(&full_path, &root_clone) {
                results.push(meta);
            }
            return results;
        }

        for entry in WalkDir::new(&full_path).into_iter().filter_map(|e| e.ok()) {
            if entry.file_type().is_file() && is_image_ext(entry.path()) {
                if let Some(meta) = process_image_metadata_sync(entry.path(), &root_clone) {
                    results.push(meta);
                }
            }
        }

        results
    })
    .await
    .unwrap_or_default();

    let scanned_paths: HashSet<String> = scanned.iter().map(|x| x.path.clone()).collect();
    let like_prefix = format!("{}/%", escape_like_pattern(&normalized));

    let mut tx = pool.begin().await?;

    for meta in scanned {
        sqlx::query("INSERT OR REPLACE INTO images (path, mtime, width, height, is_landscape) VALUES (?, ?, ?, ?, ?)")
            .bind(meta.path)
            .bind(meta.mtime)
            .bind(meta.width)
            .bind(meta.height)
            .bind(meta.is_landscape)
            .execute(&mut *tx)
            .await?;
    }

    let existing_rows: Vec<(String,)> = sqlx::query_as("SELECT path FROM images WHERE path LIKE ? ESCAPE '\\\\'")
        .bind(like_prefix)
        .fetch_all(&mut *tx)
        .await
        .unwrap_or_default();

    let mut deleted_count = 0;
    for (path,) in existing_rows {
        if !scanned_paths.contains(&path) {
            sqlx::query("DELETE FROM images WHERE path = ?")
                .bind(path)
                .execute(&mut *tx)
                .await?;
            deleted_count += 1;
        }
    }

    tx.commit().await?;
    println!(
        "ğŸ”„ [On-demand External Sync] {} | scanned {} | deleted {}",
        normalized,
        scanned_paths.len(),
        deleted_count
    );

    Ok(())
}

async fn upsert_missing_path_to_db(pool: &Pool<Sqlite>, root_dir: &Path, rel_path: &str) -> Result<()> {
    let normalized = normalize_rel_path(rel_path);
    if normalized.is_empty() || normalized == "." {
        return Ok(());
    }

    let full_path = resolve_full_path(root_dir, &normalized);
    if !full_path.exists() {
        return Ok(());
    }

    let root_clone = root_dir.to_path_buf();
    let scanned: Vec<ImageMetadata> = tokio::task::spawn_blocking(move || {
        let mut results = Vec::new();

        if full_path.is_file() {
            if let Some(meta) = process_image_metadata_sync(&full_path, &root_clone) {
                results.push(meta);
            }
            return results;
        }

        for entry in WalkDir::new(&full_path).into_iter().filter_map(|e| e.ok()) {
            if entry.file_type().is_file() && is_image_ext(entry.path()) {
                if let Some(meta) = process_image_metadata_sync(entry.path(), &root_clone) {
                    results.push(meta);
                }
            }
        }
        results
    })
    .await
    .unwrap_or_default();

    if scanned.is_empty() {
        return Ok(());
    }

    let mut tx = pool.begin().await?;
    for meta in scanned {
        sqlx::query("INSERT OR REPLACE INTO images (path, mtime, width, height, is_landscape) VALUES (?, ?, ?, ?, ?)")
            .bind(meta.path)
            .bind(meta.mtime)
            .bind(meta.width)
            .bind(meta.height)
            .bind(meta.is_landscape)
            .execute(&mut *tx)
            .await?;
    }
    tx.commit().await?;

    Ok(())
}

// --- æ ¸å¿ƒé€»è¾‘ï¼šæ‰«æä¸æ•°æ®åº“ ---

/// åˆå§‹åŒ–æ•°æ®åº“è¡¨
async fn init_db(pool: &Pool<Sqlite>) -> Result<()> {
    sqlx::query(
        "CREATE TABLE IF NOT EXISTS images (
            path TEXT PRIMARY KEY, 
            mtime REAL, 
            width INTEGER, 
            height INTEGER, 
            is_landscape BOOLEAN
        );
        CREATE TABLE IF NOT EXISTS playlists (
            client_ip TEXT PRIMARY KEY,
            playlist TEXT NOT NULL,
            created_at REAL NOT NULL
        );"
    )
    .execute(pool)
    .await?;
    Ok(())
}

/// é˜»å¡æ“ä½œï¼šè¯»å–å•ä¸ªå›¾ç‰‡çš„å…ƒæ•°æ®
fn process_image_metadata_sync(full_path: &Path, root_dir: &Path) -> Option<ImageMetadata> {
    if !full_path.exists() { return None; }
    
    // è·å–ä¿®æ”¹æ—¶é—´
    let mtime = full_path.metadata().ok()
        .and_then(|m| m.modified().ok())
        .and_then(|t| t.duration_since(UNIX_EPOCH).ok())
        .map(|d| d.as_secs_f64())
        .unwrap_or(0.0);

    // è·å–å›¾ç‰‡å°ºå¯¸ (åªè¯»å–å¤´éƒ¨ï¼Œä¸åŠ è½½æ•´ä¸ªæ–‡ä»¶)
    let (width, height) = image::image_dimensions(full_path).ok()?;
    let is_landscape = width >= height;

    // è®¡ç®—ç›¸å¯¹è·¯å¾„
    let rel_path = diff_paths(full_path, root_dir)?;
    let rel_path_str = rel_path.to_string_lossy().replace('\\', "/");

    Some(ImageMetadata {
        path: rel_path_str,
        mtime,
        width,
        height,
        is_landscape,
    })
}

/// åå°æ‰«æä»»åŠ¡
async fn scan_library_task(pool: Pool<Sqlite>, root_dir: Arc<PathBuf>) {
    println!("ğŸ” [Background] å¼€å§‹å…¨é‡æ‰«æ...");
    let start = std::time::Instant::now();

    // 1. éå†æ–‡ä»¶ç³»ç»Ÿ (FS)
    // ä½¿ç”¨ spawn_blocking é¿å…é˜»å¡ Tokio è¿è¡Œæ—¶
    let root_clone = root_dir.clone();
    let fs_files: HashMap<String, PathBuf> = tokio::task::spawn_blocking(move || {
        let mut map = HashMap::new();
        for entry in WalkDir::new(&*root_clone).into_iter().filter_map(|e| e.ok()) {
            if entry.file_type().is_file() && is_image_ext(entry.path()) {
                if let Some(rel) = diff_paths(entry.path(), &*root_clone) {
                    let rel_str = rel.to_string_lossy().replace('\\', "/");
                    map.insert(rel_str, entry.path().to_path_buf());
                }
            }
        }
        map
    }).await.unwrap();

    // 2. è·å–æ•°æ®åº“ç°æœ‰è®°å½•
    let db_rows = sqlx::query("SELECT path, mtime FROM images")
        .fetch_all(&pool)
        .await
        .unwrap_or_default();
    
    let db_files: HashMap<String, f64> = db_rows.into_iter()
        .map(|row| (row.get("path"), row.get("mtime")))
        .collect();

    // 3. æ‰¾å‡ºéœ€è¦æ›´æ–°æˆ–æ’å…¥çš„æ–‡ä»¶
    let mut to_process = Vec::new();
    for (path, full_path) in &fs_files {
        // å¦‚æœ DB é‡Œæ²¡æœ‰ï¼Œæˆ–è€… mtime ä¸ä¸€è‡´ï¼Œåˆ™éœ€è¦å¤„ç†
        let mtime = full_path.metadata().ok()
            .and_then(|m| m.modified().ok())
            .and_then(|t| t.duration_since(UNIX_EPOCH).ok())
            .map(|d| d.as_secs_f64())
            .unwrap_or(0.0);

        if !db_files.contains_key(path) || (db_files.get(path).unwrap() - mtime).abs() > 0.001 {
            to_process.push(full_path.clone());
        }
    }

    // 4. å¹¶å‘å¤„ç†å…ƒæ•°æ®è¯»å– (Bounded Parallelism)
    if !to_process.is_empty() {
        println!("ğŸš€ [Background] å‘ç° {} ä¸ªå˜åŠ¨æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...", to_process.len());
        let mut updates = Vec::new();
        
        // ä½¿ç”¨ stream å¤„ç†å¹¶å‘ï¼Œé¿å…ç¬é—´å¼€å¯è¿‡å¤šçº¿ç¨‹
        let stream = futures::stream::iter(to_process)
            .map(|path| {
                let root = root_dir.clone();
                tokio::task::spawn_blocking(move || process_image_metadata_sync(&path, &root))
            })
            .buffer_unordered(16); // æ§åˆ¶å¹¶å‘æ•°ä¸º 16

        let mut processed_stream = stream;
        while let Some(result) = processed_stream.next().await {
            if let Ok(Some(meta)) = result {
                updates.push(meta);
            }
        }

        // æ‰¹é‡å†™å…¥æ•°æ®åº“ (äº‹åŠ¡)
        if !updates.is_empty() {
            let mut tx = pool.begin().await.unwrap();
            for meta in updates {
                sqlx::query("INSERT OR REPLACE INTO images (path, mtime, width, height, is_landscape) VALUES (?, ?, ?, ?, ?)")
                    .bind(meta.path)
                    .bind(meta.mtime)
                    .bind(meta.width)
                    .bind(meta.height)
                    .bind(meta.is_landscape)
                    .execute(&mut *tx)
                    .await.ok();
            }
            tx.commit().await.unwrap();
        }
    }

    // 5. æ¸…ç†å¤±æ•ˆæ–‡ä»¶ (ä»…æ¸…ç† Root ä¸‹çš„)
    let mut deleted_count = 0;
    for db_path in db_files.keys() {
        // ç®€å•åˆ¤æ–­ï¼šå¦‚æœåœ¨ root ç›®å½•ä¸‹ä¸” fs æ‰«ææ²¡æ‰«åˆ°ï¼Œå°±åˆ æ‰
        // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ›´ä¸¥è°¨çš„è·¯å¾„åˆ¤æ–­é€»è¾‘é˜²æ­¢åˆ é™¤å¤–éƒ¨æŒ‚è½½çš„è®°å½•ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        if !fs_files.contains_key(db_path) && !db_path.starts_with("../") {
            sqlx::query("DELETE FROM images WHERE path = ?")
                .bind(db_path)
                .execute(&pool)
                .await.ok();
            deleted_count += 1;
        }
    }

    println!("âœ… [Background] æ‰«æå®Œæˆï¼Œè€—æ—¶ {:.2}sï¼Œæ¸…ç† {}", start.elapsed().as_secs_f64(), deleted_count);
}

// --- Handlers ---

async fn trigger_scan(State(state): State<AppState>) -> Json<serde_json::Value> {
    tokio::spawn(async move {
        scan_library_task(state.db, state.root_dir).await;
    });
    Json(serde_json::json!({ "status": "scanning_started" }))
}

async fn get_playlist(
    State(state): State<AppState>,
    connect_info: ConnectInfo<SocketAddr>,
    Json(req): Json<PlaylistRequest>,
) -> Json<Vec<String>> {
    let root_dir = state.root_dir.as_path();
    let allow_parent = *state.allow_parent_dir_access.read().await;

    // 1. è·¯å¾„æ¸…æ´—
    let mut valid_req_paths = Vec::new();
    for p in req.paths {
        let rel = normalize_rel_path(&p);
        let full = resolve_full_path(root_dir, &rel);
        
        // æƒé™æ£€æŸ¥
        if !allow_parent && !is_under_root(root_dir, &full) {
            valid_req_paths.push(".".to_string()); // fallback to root
        } else {
            valid_req_paths.push(rel);
        }
    }
    let mut seen_req = HashSet::new();
    valid_req_paths.retain(|p| seen_req.insert(p.clone()));

    let mut external_paths = Vec::new();
    let mut external_seen = HashSet::new();
    for p in &valid_req_paths {
        if p.is_empty() || p == "." {
            continue;
        }
        let full = resolve_full_path(root_dir, p);
        if !is_under_root(root_dir, &full) && external_seen.insert(p.clone()) {
            external_paths.push(p.clone());
        }
    }

    for ext_path in external_paths {
        let already_synced = {
            let guard = state.external_synced_paths_this_boot.read().await;
            guard.contains(&ext_path)
        };

        if !already_synced {
            if let Err(err) = sync_external_path_to_db(&state.db, root_dir, &ext_path).await {
                eprintln!("âš ï¸ External path sync failed for {}: {}", ext_path, err);
            }
            let mut guard = state.external_synced_paths_this_boot.write().await;
            guard.insert(ext_path);
        }
    }

    let mut missing_paths = Vec::new();
    for p in &valid_req_paths {
        if p.is_empty() || p == "." {
            continue;
        }
        let exists_row: Option<(i64,)> = sqlx::query_as("SELECT 1 FROM images WHERE path LIKE ? LIMIT 1")
            .bind(format!("{}/%", p))
            .fetch_optional(&state.db)
            .await
            .unwrap_or(None);
        if exists_row.is_none() {
            missing_paths.push(p.clone());
        }
    }

    for missing in missing_paths {
        if let Err(err) = upsert_missing_path_to_db(&state.db, root_dir, &missing).await {
            eprintln!("âš ï¸ Missing-path upsert failed for {}: {}", missing, err);
        }
    }

    // 2. æ•°æ®åº“æŸ¥è¯¢ (ç›´æ¥åˆ©ç”¨ SQL ç­›é€‰ï¼Œé€Ÿåº¦æå¿«)
    // æ³¨æ„ï¼šæ„å»ºåŠ¨æ€ LIKE æŸ¥è¯¢æ¯”è¾ƒç¹çï¼Œè¿™é‡Œç®€åŒ–ä¸ºè·å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ç„¶åå†…å­˜è¿‡æ»¤
    // æˆ–è€…é’ˆå¯¹æ¯ä¸ªè·¯å¾„å‰ç¼€æŸ¥ä¸€æ¬¡
    let mut all_images = Vec::new();

    for path_prefix in &valid_req_paths {
        // å¦‚æœä¸åœ¨ DB ä¸­ï¼Œéœ€è¦è§¦å‘å³æ—¶æ‰«æ (Sync logic similar to Python)
        // ä¸ºç®€åŒ–ä»£ç ï¼Œè¿™é‡Œå‡è®¾åå°æ‰«æå·²è¦†ç›–å¤§éƒ¨åˆ†ã€‚
        // ç”Ÿäº§ç¯å¢ƒåº”åœ¨æ­¤å¤„æ£€æµ‹ DB miss å¹¶å›å¡«ã€‚

        let (mut query_builder, maybe_prefix_pattern): (String, Option<String>) = if path_prefix == "." || path_prefix.is_empty() {
            ("SELECT * FROM images WHERE path NOT LIKE '../%'".to_string(), None)
        } else {
            (
                "SELECT * FROM images WHERE path LIKE ?".to_string(),
                Some(format!("{}/%", path_prefix)),
            )
        };

        if !allow_parent && path_prefix != "." && !path_prefix.is_empty() {
            query_builder.push_str(" AND path NOT LIKE '../%'");
        }
        
        if req.orientation == "Landscape" {
            query_builder.push_str(" AND is_landscape = 1");
        } else if req.orientation == "Portrait" {
            query_builder.push_str(" AND is_landscape = 0");
        }

        let rows = if let Some(prefix_pattern) = maybe_prefix_pattern {
            sqlx::query_as::<_, ImageMetadata>(&query_builder)
                .bind(prefix_pattern)
                .fetch_all(&state.db)
                .await
                .unwrap_or_default()
        } else {
            sqlx::query_as::<_, ImageMetadata>(&query_builder)
                .fetch_all(&state.db)
                .await
                .unwrap_or_default()
        };
        
        all_images.extend(rows);
    }

    // å»é‡
    let mut seen = HashSet::new();
    all_images.retain(|i| seen.insert(i.path.clone()));

    // 3. æ’åº
    match req.sort.as_str() {
        "shuffle" => all_images.shuffle(&mut rand::thread_rng()),
        "date" => all_images.sort_by(|a, b| b.mtime.partial_cmp(&a.mtime).unwrap()),
        "name" => all_images.sort_by(|a, b| natord::compare_ignore_case(&a.path, &b.path)),
        "subfolder_random" => {
            let mut grouped: HashMap<String, Vec<ImageMetadata>> = HashMap::new();
            for item in all_images {
                grouped.entry(parent_folder(&item.path)).or_default().push(item);
            }

            let mut subfolders: Vec<String> = grouped.keys().cloned().collect();
            subfolders.shuffle(&mut rand::thread_rng());

            let mut flattened = Vec::new();
            for folder in subfolders {
                if let Some(mut items) = grouped.remove(&folder) {
                    items.sort_by(|a, b| natord::compare_ignore_case(&a.path, &b.path));
                    flattened.extend(items);
                }
            }
            all_images = flattened;
        }
        "subfolder_date" => {
            let mut grouped: HashMap<String, Vec<ImageMetadata>> = HashMap::new();
            for item in all_images {
                grouped.entry(parent_folder(&item.path)).or_default().push(item);
            }

            let mut subfolders: Vec<String> = grouped.keys().cloned().collect();
            subfolders.sort_by(|a, b| {
                let ma = folder_mtime(root_dir, a);
                let mb = folder_mtime(root_dir, b);
                ma.partial_cmp(&mb).unwrap_or(std::cmp::Ordering::Equal)
            });

            let mut flattened = Vec::new();
            for folder in subfolders {
                if let Some(mut items) = grouped.remove(&folder) {
                    items.sort_by(|a, b| natord::compare_ignore_case(&a.path, &b.path));
                    flattened.extend(items);
                }
            }
            all_images = flattened;
        }
        "subfolder_prefix" => {
            let mut grouped: HashMap<String, Vec<ImageMetadata>> = HashMap::new();
            for item in all_images {
                grouped.entry(parent_folder(&item.path)).or_default().push(item);
            }

            let mut folder_orders: Vec<(String, String)> = Vec::new();
            for (folder, items) in &mut grouped {
                items.sort_by(|a, b| natord::compare_ignore_case(&a.path, &b.path));
                let prefix = folder_first_image_prefix(items);
                folder_orders.push((folder.clone(), prefix));
            }

            folder_orders.sort_by(|(folder_a, prefix_a), (folder_b, prefix_b)| {
                natord::compare_ignore_case(prefix_a, prefix_b)
                    .then_with(|| natord::compare_ignore_case(folder_a, folder_b))
            });

            let mut flattened = Vec::new();
            for (folder, _) in folder_orders {
                if let Some(items) = grouped.remove(&folder) {
                    flattened.extend(items);
                }
            }
            all_images = flattened;
        }
        _ => all_images.sort_by(|a, b| natord::compare_ignore_case(&a.path, &b.path)),
    }

    let mut final_paths: Vec<String> = all_images.into_iter().map(|i| i.path).collect();

    if req.direction == "reverse" {
        final_paths.reverse();
    }

    // 4. å½“å‰ä½ç½®æ—‹è½¬
    if let Some(curr) = req.current_path {
        let curr_norm = normalize_rel_path(&curr);
        if let Some(pos) = final_paths.iter().position(|x| x == &curr_norm) {
            final_paths.rotate_left(pos);
        }
    }

    // 5. æŒä¹…åŒ–åˆ°æ•°æ®åº“ (å…³é”®åŠŸèƒ½æ¢å¤)
    let ip = connect_info.0.ip().to_string();
    if let Ok(json_playlist) = serde_json::to_string(&final_paths) {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs_f64();
        sqlx::query("INSERT OR REPLACE INTO playlists (client_ip, playlist, created_at) VALUES (?, ?, ?)")
            .bind(&ip)
            .bind(json_playlist)
            .bind(now)
            .execute(&state.db)
            .await
            .ok();
    }

    {
        let mut sessions = state.user_sessions.write().await;
        sessions.insert(ip.clone(), final_paths.clone());
    }

    Json(final_paths)
}

async fn restore_playlist(
    State(state): State<AppState>,
    connect_info: ConnectInfo<SocketAddr>,
    Json(req): Json<RestorePlaylistRequest>,
) -> Result<Json<serde_json::Value>, (StatusCode, Json<serde_json::Value>)> {
    let original_count = req.playlist.len();
    println!("ğŸ”„ [Restore Playlist] è¯·æ±‚æ¢å¤æ’­æ”¾åˆ—è¡¨ï¼ŒåŸå§‹è·¯å¾„æ•°é‡: {}", original_count);
    if original_count == 0 {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(serde_json::json!({ "detail": "Playlist cannot be empty" })),
        ));
    }

    let root_dir = state.root_dir.as_path();
    let allow_parent = *state.allow_parent_dir_access.read().await;

    // éªŒè¯è·¯å¾„æœ‰æ•ˆæ€§ (ä½¿ç”¨ fs é DBï¼Œç¡®ä¿æ–‡ä»¶ç¡®å®è¿˜åœ¨)
    let mut valid_paths = Vec::new();
    for p in req.playlist {
        let rel = normalize_rel_path(&p);
        let full = resolve_full_path(root_dir, &rel);
        if full.is_file() {
            if allow_parent || is_under_root(root_dir, &full) {
                valid_paths.push(rel);
            }
        }
    }

    if valid_paths.is_empty() {
        return Err((
            StatusCode::BAD_REQUEST,
            Json(serde_json::json!({ "detail": "No valid paths in playlist" })),
        ));
    }

    // æ›´æ–°æ•°æ®åº“ä¼šè¯
    let ip = connect_info.0.ip().to_string();
    if let Ok(json_playlist) = serde_json::to_string(&valid_paths) {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs_f64();
        sqlx::query("INSERT OR REPLACE INTO playlists (client_ip, playlist, created_at) VALUES (?, ?, ?)")
            .bind(&ip)
            .bind(json_playlist)
            .bind(now)
            .execute(&state.db)
            .await
            .ok();
    }

    {
        let mut sessions = state.user_sessions.write().await;
        sessions.insert(ip.clone(), valid_paths.clone());
    }

    let current_index = req.current_index.min(valid_paths.len().saturating_sub(1));

    Ok(Json(serde_json::json!({
        "status": "restored",
        "valid_count": valid_paths.len(),
        "original_count": original_count,
        "current_index": current_index,
        "playlist": valid_paths
    })))
}

async fn session_status(
    State(state): State<AppState>,
    connect_info: ConnectInfo<SocketAddr>,
) -> Json<SessionStatusResponse> {
    let ip = connect_info.0.ip().to_string();

    {
        let sessions = state.user_sessions.read().await;
        if let Some(playlist) = sessions.get(&ip) {
            return Json(SessionStatusResponse {
                has_session: true,
                source: Some("memory".to_string()),
                playlist_size: playlist.len(),
            });
        }
    }
    
    // ä»æ•°æ®åº“æŸ¥è¯¢
    let row: Option<(String,)> = sqlx::query_as("SELECT playlist FROM playlists WHERE client_ip = ?")
        .bind(&ip)
        .fetch_optional(&state.db)
        .await
        .unwrap_or(None);

    if let Some((playlist_json,)) = row {
        if let Ok(list) = serde_json::from_str::<Vec<String>>(&playlist_json) {
            return Json(SessionStatusResponse {
                has_session: true,
                source: Some("database".to_string()),
                playlist_size: list.len(),
            });
        }
    }

    Json(SessionStatusResponse { has_session: false, source: None, playlist_size: 0 })
}

async fn session_playlist(
    State(state): State<AppState>,
    connect_info: ConnectInfo<SocketAddr>,
) -> Json<SessionPlaylistResponse> {
    let ip = connect_info.0.ip().to_string();

    {
        let sessions = state.user_sessions.read().await;
        if let Some(playlist) = sessions.get(&ip) {
            return Json(SessionPlaylistResponse {
                has_session: true,
                source: Some("memory".to_string()),
                playlist_size: playlist.len(),
                playlist: playlist.clone(),
            });
        }
    }

    let row: Option<(String,)> = sqlx::query_as("SELECT playlist FROM playlists WHERE client_ip = ?")
        .bind(&ip)
        .fetch_optional(&state.db)
        .await
        .unwrap_or(None);

    if let Some((playlist_json,)) = row {
        if let Ok(list) = serde_json::from_str::<Vec<String>>(&playlist_json) {
            return Json(SessionPlaylistResponse {
                has_session: true,
                source: Some("database".to_string()),
                playlist_size: list.len(),
                playlist: list,
            });
        }
    }

    Json(SessionPlaylistResponse {
        has_session: false,
        source: None,
        playlist_size: 0,
        playlist: Vec::new(),
    })
}

// ç®€å•çš„æ–‡ä»¶æœåŠ¡ï¼Œä¸å¸¦ç¼“å­˜é€»è¾‘ï¼Œä¾é  OS Page Cache
// --- æ–‡ä»¶æœåŠ¡é€»è¾‘ ---

/// æ ¸å¿ƒæ–‡ä»¶è¯»å–é€»è¾‘
async fn serve_file_core(state: AppState, raw_path: String) -> Response {
    let root_dir = state.root_dir.as_path();
    let allow_parent = *state.allow_parent_dir_access.read().await;
    
    // 1. URL è§£ç  (éå¸¸é‡è¦ï¼å‰ç«¯ä¼ è¿‡æ¥çš„å¯èƒ½æ˜¯ "foo%20bar.jpg")
    // axum::extract::Path ä¼šè‡ªåŠ¨è§£ç ï¼Œä½† Query éœ€è¦æ‰‹åŠ¨å¤„ç†æˆ–è€…ä¾èµ– serde
    // è¿™é‡Œåšä¸€æ¬¡ä»ç™¾åˆ†å·ç¼–ç çš„è§£ç ï¼Œé˜²æ­¢ raw_path ä¾ç„¶åŒ…å« %20
    let decoded_path = urlencoding::decode(&raw_path)
        .map(|s| s.into_owned())
        .unwrap_or_else(|_| raw_path.clone());

    let rel = normalize_rel_path(&decoded_path);
    let full = resolve_full_path(root_dir, &rel);

    // 2. æƒé™æ£€æŸ¥
    if !allow_parent && !is_under_root(root_dir, &full) {
        return (
            StatusCode::FORBIDDEN, 
            Json(serde_json::json!({ "message": "Access outside ROOT_DIR is disabled" }))
        ).into_response();
    }

    // 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if !full.exists() || !full.is_file() {
        return StatusCode::NOT_FOUND.into_response();
    }

    // 4. é«˜æ•ˆæµå¼ä¼ è¾“
    match tokio::fs::File::open(&full).await {
        Ok(file) => {
            let stream = tokio_util::io::ReaderStream::new(file);
            let body = axum::body::Body::from_stream(stream);

            let mime = from_path(&full).first_or_octet_stream();
            let mut headers = HeaderMap::new();
            headers.insert(header::CONTENT_TYPE, mime.as_ref().parse().unwrap());
            // ç¼“å­˜æ§åˆ¶ï¼šè®©æµè§ˆå™¨ç¼“å­˜å›¾ç‰‡ 1 å°æ—¶ï¼Œå‡å°‘æœåŠ¡å™¨å‹åŠ›
            headers.insert(header::CACHE_CONTROL, "public, max-age=3600".parse().unwrap());

            (headers, body).into_response()
        },
        Err(_) => StatusCode::INTERNAL_SERVER_ERROR.into_response(),
    }
}

/// æ¥å£ 1: å¤„ç† /api/file?path=...
async fn serve_file_by_query(
    State(state): State<AppState>,
    Query(query): Query<FileQuery>,
) -> Response {
    if state.log_api_file_requests {
        println!("ğŸ“· [API /api/file] path={}", query.path);
    }
    serve_file_core(state, query.path).await
}

/// æ¥å£ 2: å¤„ç†ç›´æ¥è·¯å¾„ /folder/image.jpg
// async fn serve_file_by_path(
//     State(state): State<AppState>,
//     AxumPath(path_str): AxumPath<String>,
// ) -> Response {
//     serve_file_core(state, path_str).await
// }

async fn browse_folder(
    State(state): State<AppState>,
    Query(query): Query<BrowseQuery>,
) -> Result<Json<BrowseResponse>, (StatusCode, Json<serde_json::Value>)> {
    let root_dir = state.root_dir.as_path();
    let allow_parent = *state.allow_parent_dir_access.read().await;

    let mut rel_path = normalize_rel_path(&query.path);
    let mut target_path = if rel_path.is_empty() || rel_path == "." {
        root_dir.to_path_buf()
    } else {
        resolve_full_path(root_dir, &rel_path)
    };

    if !allow_parent && !is_under_root(root_dir, &target_path) {
        target_path = root_dir.to_path_buf();
        rel_path.clear();
    } else {
        rel_path = path_to_rel_string(root_dir, &target_path);
        if rel_path == "." {
            rel_path.clear();
        }
    }

    if !target_path.exists() || !target_path.is_dir() {
        return Err((
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({ "detail": "Folder not found" })),
        ));
    }

    let mut items = Vec::new();
    let entries = std::fs::read_dir(&target_path).map_err(|_| {
        (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({ "detail": "Failed to read folder" })),
        )
    })?;

    for entry in entries.flatten() {
        let entry_path = entry.path();
        let name = entry.file_name().to_string_lossy().to_string();
        if name.starts_with('.') {
            continue;
        }

        let Ok(ft) = entry.file_type() else {
            continue;
        };

        let is_dir = ft.is_dir();
        if !is_dir && !is_image_ext(&entry_path) {
            continue;
        }

        items.push(BrowseItem {
            name,
            path: path_to_rel_string(root_dir, &entry_path),
            item_type: if is_dir { "folder" } else { "file" }.to_string(),
        });
    }

    items.sort_by(|a, b| {
        let rank_a = if a.item_type == "folder" { 0 } else { 1 };
        let rank_b = if b.item_type == "folder" { 0 } else { 1 };
        rank_a
            .cmp(&rank_b)
            .then_with(|| natord::compare_ignore_case(&a.name, &b.name))
    });

    Ok(Json(BrowseResponse {
        current_path: rel_path,
        items,
    }))
}

async fn get_runtime_config(State(state): State<AppState>) -> Json<serde_json::Value> {
    let v = *state.allow_parent_dir_access.read().await;
    Json(serde_json::json!({
        "allow_parent_dir_access": v,
        "env_value": env::var("GALLERY_ALLOW_PARENT_DIR_ACCESS").unwrap_or_else(|_| "<unset>".to_string())
    }))
}

async fn set_runtime_config(
    State(state): State<AppState>,
    Json(req): Json<RuntimeConfigRequest>,
) -> Json<serde_json::Value> {
    {
        let mut guard = state.allow_parent_dir_access.write().await;
        *guard = req.allow_parent_dir_access;
    }
    env::set_var(
        "GALLERY_ALLOW_PARENT_DIR_ACCESS",
        if req.allow_parent_dir_access { "1" } else { "0" },
    );

    Json(serde_json::json!({
        "status": "ok",
        "allow_parent_dir_access": req.allow_parent_dir_access,
        "env_value": env::var("GALLERY_ALLOW_PARENT_DIR_ACCESS").unwrap_or_else(|_| "<unset>".to_string())
    }))
}

async fn toggle_runtime_config(State(state): State<AppState>) -> Json<serde_json::Value> {
    let new_value = {
        let mut guard = state.allow_parent_dir_access.write().await;
        *guard = !*guard;
        *guard
    };

    env::set_var(
        "GALLERY_ALLOW_PARENT_DIR_ACCESS",
        if new_value { "1" } else { "0" },
    );

    Json(serde_json::json!({
        "status": "ok",
        "allow_parent_dir_access": new_value,
        "env_value": env::var("GALLERY_ALLOW_PARENT_DIR_ACCESS").unwrap_or_else(|_| "<unset>".to_string())
    }))
}

// --- Main ---

#[tokio::main]
async fn main() -> Result<()> {
        let host = env::var("GALLERY_HOST").unwrap_or_else(|_| "0.0.0.0".to_string());
        let port = env::var("GALLERY_PORT")
            .ok()
            .and_then(|v| v.parse::<u16>().ok())
            .unwrap_or(4860);

    // 1. ç¯å¢ƒé…ç½®
    let root_dir = env::var("GALLERY_ROOT_DIR").map(PathBuf::from).unwrap_or(env::current_dir()?);
    let db_path = root_dir.join("gallery_metadata.db");
    
    // 2. æ•°æ®åº“è¿æ¥æ± 
    let db_url = format!("sqlite://{}?mode=rwc", db_path.to_string_lossy());
    let pool = SqlitePoolOptions::new()
        .max_connections(10)
        .connect(&db_url)
        .await
        .expect("Failed to connect to SQLite");
    
    init_db(&pool).await?;

    let app_state = AppState {
        db: pool.clone(),
        root_dir: Arc::new(root_dir.clone()),
        allow_parent_dir_access: Arc::new(RwLock::new(env::var("GALLERY_ALLOW_PARENT_DIR_ACCESS").unwrap_or_default() == "1")),
        external_synced_paths_this_boot: Arc::new(RwLock::new(HashSet::new())),
        user_sessions: Arc::new(RwLock::new(HashMap::new())),
        log_api_file_requests: env_flag_enabled("GALLERY_LOG_API_FILE_REQUESTS"),
    };

    println!(
        "ğŸ“ API /api/file request logging: {}",
        if app_state.log_api_file_requests { "ON" } else { "OFF" }
    );

    // å¯åŠ¨æ—¶è§¦å‘ä¸€æ¬¡æ‰«æ
    let state_clone = app_state.clone();
    tokio::spawn(async move {
        scan_library_task(state_clone.db, state_clone.root_dir).await;
    });

    // 3. è·¯ç”±
    let app = Router::new()
        .route("/api/scan", post(trigger_scan))
        .route("/api/browse", get(browse_folder))
        .route("/api/playlist", post(get_playlist))
        .route("/api/restore-playlist", post(restore_playlist))
        .route("/api/session-status", get(session_status))
        .route("/api/session-playlist", get(session_playlist))
        .route("/api/runtime-config", get(get_runtime_config).post(set_runtime_config))
        .route("/api/runtime-config/toggle", post(toggle_runtime_config))
        // --- ä¿®å¤ç‚¹å¼€å§‹ ---
        .route("/api/file", get(serve_file_by_query)) // å¿…é¡»æ”¾åœ¨é€šé…ç¬¦ä¹‹å‰
        // .route("/*file_path", get(serve_file_by_path))
        // --- ä¿®å¤ç‚¹ç»“æŸ ---
        .layer(CorsLayer::permissive())
        .with_state(app_state);

    // 4. æœåŠ¡å™¨å¯åŠ¨ (Rustls)
    let addr: SocketAddr = format!("{}:{}", host, port)
        .parse()
        .unwrap_or_else(|_| SocketAddr::from(([0, 0, 0, 0], 4860)));
    println!("ğŸš€ Rust Gallery Server running on https://{}", addr);
    
    // åŠ è½½è¯ä¹¦éƒ¨åˆ†çœç•¥ï¼Œé€»è¾‘åŒä¸Š... å‡è®¾è¯ä¹¦å­˜åœ¨
    if let (Ok(cert), Ok(key)) = (env::var("GALLERY_SSL_CERT"), env::var("GALLERY_SSL_KEY")) {
         let tls_config = RustlsConfig::from_pem_file(cert, key).await?;
         axum_server::bind_rustls(addr, tls_config)
            .serve(app.into_make_service_with_connect_info::<SocketAddr>())
            .await?;
    } else {
        println!("âš ï¸  SSLæœªé…ç½®ï¼Œè¿è¡Œåœ¨ HTTP æ¨¡å¼");
        axum_server::bind(addr)
            .serve(app.into_make_service_with_connect_info::<SocketAddr>())
            .await?;
    }

    Ok(())
}